{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5e1253",
   "metadata": {},
   "source": [
    "# Generate Tim Fletcher Style Therapeutic Conversations\n",
    "\n",
    "**GPU**: Google Colab Free Tier (T4)  \n",
    "**Purpose**: Generate synthetic therapeutic conversations in Tim Fletcher's teaching voice  \n",
    "**Input**: Tim Fletcher voice profile (extracted from 913 transcripts)  \n",
    "**Output**: Training dataset for Stage 3 (voice injection)\n",
    "\n",
    "---\n",
    "\n",
    "## Setup\n",
    "\n",
    "**Before running**:\n",
    "1. Runtime â†’ Change runtime type â†’ T4 GPU\n",
    "2. Upload `tim_fletcher_voice_profile.json` to Colab\n",
    "3. Set your HuggingFace token (for model access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ba062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84948cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q transformers accelerate bitsandbytes scipy\n",
    "%pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d21e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from typing import List, Dict\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'None'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9849544b",
   "metadata": {},
   "source": [
    "## Load Tim Fletcher Voice Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload tim_fletcher_voice_profile.json first, or load from Google Drive\n",
    "# Option 1: Upload file\n",
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load voice profile\n",
    "with open('tim_fletcher_voice_profile.json', 'r') as f:\n",
    "    voice_profile = json.load(f)\n",
    "\n",
    "print(\"Voice Profile Loaded:\")\n",
    "print(f\"  Sentence starters: {len(voice_profile['sentence_starters'])}\")\n",
    "print(f\"  Transition phrases: {len(voice_profile['transition_phrases'])}\")\n",
    "print(f\"  Empathy markers: {len(voice_profile['empathy_markers'])}\")\n",
    "print(f\"  Analogies: {len(voice_profile['analogies'])}\")\n",
    "print(f\"  Examples: {len(voice_profile['examples'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07208831",
   "metadata": {},
   "source": [
    "## Load Language Model (4-bit Quantized for Free Tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77b4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection - using a good instruction-following model\n",
    "MODEL_NAME = \"mistralai/Mistral-7B-Instruct-v0.2\"  # Fast and good quality\n",
    "# Alternative: \"meta-llama/Llama-2-7b-chat-hf\" (requires HF token)\n",
    "\n",
    "# 4-bit quantization config for free GPU\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"âœ… Model loaded successfully!\")\n",
    "print(f\"Model memory footprint: {model.get_memory_footprint() / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2482225b",
   "metadata": {},
   "source": [
    "## Create Tim Fletcher Voice System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ebcd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tim_fletcher_prompt(voice_profile: Dict) -> str:\n",
    "    \"\"\"Create system prompt that captures Tim's voice\"\"\"\n",
    "\n",
    "    prompt = \"\"\"You are a therapeutic AI assistant trained to speak in Tim Fletcher's teaching voice.\n",
    "\n",
    "TIM FLETCHER'S VOICE CHARACTERISTICS:\n",
    "\n",
    "SENTENCE STARTERS (use frequently):\n",
    "\"\"\"\n",
    "    # Top 10 sentence starters\n",
    "    starters = list(voice_profile['sentence_starters'].items())[:10]\n",
    "    for starter, count in starters:\n",
    "        prompt += f\"- \\\"{starter}...\\\"\\n\"\n",
    "\n",
    "    prompt += \"\\nTRANSITION PHRASES (connect ideas):\\n\"\n",
    "    for phrase in list(voice_profile['transition_phrases'].keys())[:8]:\n",
    "        prompt += f\"- \\\"{phrase}\\\"\\n\"\n",
    "\n",
    "    prompt += \"\\nEMPATHY MARKERS (show understanding):\\n\"\n",
    "    for marker in list(voice_profile['empathy_markers'].keys())[:8]:\n",
    "        prompt += f\"- \\\"{marker}\\\"\\n\"\n",
    "\n",
    "    prompt += \"\"\"\\nTEACHING STYLE:\n",
    "- Break down complex concepts into simple steps\n",
    "- Use numbered points (First, Second, Third)\n",
    "- Give concrete examples with \\\"Let's say\\\" or \\\"Think about\\\"\n",
    "- Use analogies: \\\"It's like...\\\" or \\\"Imagine...\\\"\n",
    "- Normalize experiences: \\\"Many people...\\\" \\\"For some people...\\\"\n",
    "- Show deep empathy and understanding\n",
    "- Connect to real-life scenarios\n",
    "- Focus on complex trauma, PTSD, recovery concepts\n",
    "\n",
    "EXAMPLE ANALOGIES:\n",
    "\"\"\"\n",
    "    for analogy in voice_profile['analogies'][:3]:\n",
    "        prompt += f\"- {analogy}\\n\"\n",
    "\n",
    "    prompt += \"\\nEXAMPLE EXPRESSIONS:\\n\"\n",
    "    for example in voice_profile['examples'][:3]:\n",
    "        prompt += f\"- {example}\\n\"\n",
    "\n",
    "    prompt += \"\"\"\\nYour responses should:\n",
    "1. Sound natural and conversational (like Tim speaking)\n",
    "2. Show deep understanding of complex trauma\n",
    "3. Use Tim's characteristic phrases and transitions\n",
    "4. Include examples and analogies\n",
    "5. Be compassionate and educational\n",
    "\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# Create the prompt\n",
    "tim_system_prompt = create_tim_fletcher_prompt(voice_profile)\n",
    "print(\"âœ… Tim Fletcher voice prompt created\")\n",
    "print(f\"\\nPrompt preview (first 500 chars):\\n{tim_system_prompt[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4da4e5e",
   "metadata": {},
   "source": [
    "## Conversation Topics (Complex Trauma Focus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b67dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics from Tim Fletcher's teachings\n",
    "CONVERSATION_TOPICS = [\n",
    "    # Complex Trauma Characteristics\n",
    "    \"fear of abandonment and rejection\",\n",
    "    \"difficulty trusting others\",\n",
    "    \"emotional dysregulation and mood swings\",\n",
    "    \"shame and negative self-identity\",\n",
    "    \"hypervigilance and always being on alert\",\n",
    "    \"difficulty with change and transitions\",\n",
    "    \"people-pleasing and loss of self\",\n",
    "    \"impulsive behaviors and self-sabotage\",\n",
    "    \"dissociation and feeling numb\",\n",
    "    \"maladaptive coping mechanisms\",\n",
    "\n",
    "    # PTSD & Recovery\n",
    "    \"flashbacks and intrusive memories\",\n",
    "    \"triggers and how to manage them\",\n",
    "    \"building healthy attachments\",\n",
    "    \"learning to regulate emotions\",\n",
    "    \"processing childhood wounds\",\n",
    "    \"healing from narcissistic abuse\",\n",
    "    \"breaking trauma bonds\",\n",
    "    \"developing self-compassion\",\n",
    "    \"understanding the limbic brain vs cortex\",\n",
    "    \"creating safety and stability\",\n",
    "\n",
    "    # Relationships\n",
    "    \"fear of intimacy and vulnerability\",\n",
    "    \"setting healthy boundaries\",\n",
    "    \"recognizing unhealthy relationship patterns\",\n",
    "    \"dealing with conflict in relationships\",\n",
    "    \"impact of trauma on parenting\",\n",
    "    \"recovering from codependency\",\n",
    "\n",
    "    # Specific Issues\n",
    "    \"anger and resentment from past hurt\",\n",
    "    \"grief and loss in trauma recovery\",\n",
    "    \"perfectionism as a trauma response\",\n",
    "    \"addiction and compulsive behaviors\",\n",
    "    \"anxiety and panic attacks\",\n",
    "    \"depression and hopelessness\",\n",
    "    \"spiritual crisis after trauma\",\n",
    "    \"forgiving those who hurt you\",\n",
    "    \"rebuilding identity after trauma\",\n",
    "]\n",
    "\n",
    "print(f\"ðŸ“‹ {len(CONVERSATION_TOPICS)} conversation topics loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6806345",
   "metadata": {},
   "source": [
    "## Client Message Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7d2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realistic client opening messages\n",
    "CLIENT_TEMPLATES = [\n",
    "    \"I've been struggling with {topic}. It's been affecting my daily life.\",\n",
    "    \"Can you help me understand {topic}? I don't know where to start.\",\n",
    "    \"I think I'm dealing with {topic}, but I'm not sure what to do about it.\",\n",
    "    \"I've noticed patterns of {topic} in my life. How do I break free from this?\",\n",
    "    \"I'm having a really hard time with {topic}. It feels overwhelming.\",\n",
    "    \"I grew up in a difficult environment and now I'm experiencing {topic}.\",\n",
    "    \"Ever since I can remember, I've dealt with {topic}. Is this related to my childhood?\",\n",
    "    \"I want to heal from {topic}, but I don't know how.\",\n",
    "    \"My therapist mentioned {topic}. Can you explain what that means?\",\n",
    "    \"I keep finding myself stuck in {topic}. What's happening to me?\",\n",
    "]\n",
    "\n",
    "# Follow-up client responses\n",
    "CLIENT_FOLLOWUPS = [\n",
    "    \"That makes sense. Can you give me an example?\",\n",
    "    \"I think I understand. But what do I do when this gets triggered?\",\n",
    "    \"This is really helpful. How long does healing from this usually take?\",\n",
    "    \"I've tried to work on this before but always fall back. Why does that happen?\",\n",
    "    \"What you're saying resonates with me. Where should I start?\",\n",
    "    \"I'm worried I'll never get better. Is that normal to feel?\",\n",
    "    \"This is hard to hear, but it's true. What's the next step?\",\n",
    "    \"I can see how my childhood relates to this now. How do I move forward?\",\n",
    "]\n",
    "\n",
    "print(f\"âœ… Client templates loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3ca882",
   "metadata": {},
   "source": [
    "## Conversation Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3db6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_therapist_response(client_message: str, conversation_history: List[Dict], max_length: int = 512) -> str:\n",
    "    \"\"\"Generate therapist response in Tim Fletcher's voice\"\"\"\n",
    "\n",
    "    # Build conversation context\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": tim_system_prompt},\n",
    "    ]\n",
    "\n",
    "    # Add conversation history\n",
    "    for turn in conversation_history:\n",
    "        role = \"user\" if turn[\"role\"] == \"client\" else \"assistant\"\n",
    "        messages.append({\"role\": role, \"content\": turn[\"content\"]})\n",
    "\n",
    "    # Add current client message\n",
    "    messages.append({\"role\": \"user\", \"content\": client_message})\n",
    "\n",
    "    # Format for model\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    # Generate response\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=0.8,\n",
    "            top_p=0.9,\n",
    "            do_sample=True,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "    response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "    return response.strip()\n",
    "\n",
    "\n",
    "def generate_conversation(topic: str, num_turns: int = 4) -> Dict:\n",
    "    \"\"\"Generate a full therapeutic conversation\"\"\"\n",
    "\n",
    "    conversation = []\n",
    "\n",
    "    # Client opening\n",
    "    opening_template = random.choice(CLIENT_TEMPLATES)\n",
    "    client_opening = opening_template.format(topic=topic)\n",
    "    conversation.append({\"role\": \"client\", \"content\": client_opening})\n",
    "\n",
    "    # Generate multi-turn conversation\n",
    "    for turn in range(num_turns):\n",
    "        # Therapist response\n",
    "        therapist_response = generate_therapist_response(\n",
    "            conversation[-1][\"content\"],\n",
    "            conversation[:-1]\n",
    "        )\n",
    "        conversation.append({\"role\": \"therapist\", \"content\": therapist_response})\n",
    "\n",
    "        # Client follow-up (except on last turn)\n",
    "        if turn < num_turns - 1:\n",
    "            client_followup = random.choice(CLIENT_FOLLOWUPS)\n",
    "            conversation.append({\"role\": \"client\", \"content\": client_followup})\n",
    "\n",
    "    return {\n",
    "        \"conversation\": conversation,\n",
    "        \"metadata\": {\n",
    "            \"source\": \"tim_fletcher_synthetic\",\n",
    "            \"topic\": topic,\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"turns\": len(conversation)\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"âœ… Conversation generator ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1947759",
   "metadata": {},
   "source": [
    "## Test Generation (Single Conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff30e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with one conversation\n",
    "print(\"ðŸ§ª Testing conversation generation...\\n\")\n",
    "\n",
    "test_topic = random.choice(CONVERSATION_TOPICS)\n",
    "print(f\"Topic: {test_topic}\\n\")\n",
    "\n",
    "test_conversation = generate_conversation(test_topic, num_turns=2)\n",
    "\n",
    "# Display conversation\n",
    "for i, turn in enumerate(test_conversation['conversation'], 1):\n",
    "    role = turn['role'].upper()\n",
    "    content = turn['content']\n",
    "    print(f\"[{role}]: {content}\\n\")\n",
    "\n",
    "print(\"\\nâœ… Test successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c3db8",
   "metadata": {},
   "source": [
    "## Generate Full Dataset (1000 Conversations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f724abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "NUM_CONVERSATIONS = 1000\n",
    "TURNS_PER_CONVERSATION = 4  # 4-8 exchanges\n",
    "\n",
    "print(f\"ðŸŽ¨ Generating {NUM_CONVERSATIONS} conversations...\")\n",
    "print(f\"   Turns per conversation: {TURNS_PER_CONVERSATION}\")\n",
    "print(f\"   Topics: {len(CONVERSATION_TOPICS)}\")\n",
    "print(\"\\nThis will take approximately 2-3 hours on free T4 GPU\\n\")\n",
    "\n",
    "conversations = []\n",
    "errors = []\n",
    "\n",
    "for i in tqdm(range(NUM_CONVERSATIONS), desc=\"Generating conversations\"):\n",
    "    try:\n",
    "        # Random topic\n",
    "        topic = random.choice(CONVERSATION_TOPICS)\n",
    "\n",
    "        # Random number of turns (4-6)\n",
    "        num_turns = random.randint(4, 6)\n",
    "\n",
    "        # Generate conversation\n",
    "        conversation = generate_conversation(topic, num_turns=num_turns)\n",
    "        conversations.append(conversation)\n",
    "\n",
    "        # Save checkpoint every 100 conversations\n",
    "        if (i + 1) % 100 == 0:\n",
    "            checkpoint_file = f'tim_fletcher_conversations_checkpoint_{i+1}.json'\n",
    "            with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(conversations, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"\\nðŸ’¾ Checkpoint saved: {checkpoint_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸ Error on conversation {i}: {e}\")\n",
    "        errors.append({\"index\": i, \"error\": str(e)})\n",
    "        continue\n",
    "\n",
    "print(f\"\\nâœ… Generation complete!\")\n",
    "print(f\"   Successfully generated: {len(conversations)} conversations\")\n",
    "print(f\"   Errors: {len(errors)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c929d06",
   "metadata": {},
   "source": [
    "## Save Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cfd974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final dataset\n",
    "output_file = 'tim_fletcher_synthetic_conversations.json'\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(conversations, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"ðŸ’¾ Saved {len(conversations)} conversations to {output_file}\")\n",
    "\n",
    "# Calculate statistics\n",
    "total_turns = sum(len(c['conversation']) for c in conversations)\n",
    "avg_turns = total_turns / len(conversations)\n",
    "\n",
    "print(f\"\\nðŸ“Š Dataset Statistics:\")\n",
    "print(f\"   Total conversations: {len(conversations)}\")\n",
    "print(f\"   Total turns: {total_turns}\")\n",
    "print(f\"   Average turns per conversation: {avg_turns:.1f}\")\n",
    "print(f\"   Unique topics: {len(set(c['metadata']['topic'] for c in conversations))}\")\n",
    "\n",
    "# File size\n",
    "import os\n",
    "file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "print(f\"   File size: {file_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb1ee34",
   "metadata": {},
   "source": [
    "## Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download to local machine\n",
    "from google.colab import files\n",
    "\n",
    "print(\"ðŸ“¥ Downloading dataset...\")\n",
    "files.download(output_file)\n",
    "print(\"âœ… Download complete!\")\n",
    "print(\"\\nUpload this file to: /home/vivi/pixelated/ai/data/tim_fletcher_voice/synthetic_conversations.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1621603a",
   "metadata": {},
   "source": [
    "## Sample Output Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c29d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a few sample conversations\n",
    "print(\"ðŸ“‹ Sample Conversations:\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(min(3, len(conversations))):\n",
    "    conv = conversations[i]\n",
    "    print(f\"\\n### CONVERSATION {i+1}\")\n",
    "    print(f\"Topic: {conv['metadata']['topic']}\")\n",
    "    print(f\"Turns: {conv['metadata']['turns']}\\n\")\n",
    "\n",
    "    for turn in conv['conversation']:\n",
    "        role = turn['role'].upper()\n",
    "        content = turn['content'][:200] + '...' if len(turn['content']) > 200 else turn['content']\n",
    "        print(f\"[{role}]: {content}\\n\")\n",
    "\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a593b70",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. **Download** the generated dataset\n",
    "2. **Upload** to `/home/vivi/pixelated/ai/data/tim_fletcher_voice/synthetic_conversations.json`\n",
    "3. **Review** sample conversations for quality\n",
    "4. **Update** Stage 3 training config to point to this dataset\n",
    "5. **Run** Stage 3 training on Lightning.ai H100\n",
    "\n",
    "**Expected Output**: 1000 therapeutic conversations in Tim Fletcher's teaching voice, ready for Stage 3 training"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
