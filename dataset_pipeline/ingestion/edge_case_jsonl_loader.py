#!/usr/bin/env python3
"""
Edge Case JSONL Loader for Training Pipeline Integration
Loads edge case training data generated by the standalone pipeline
"""

import json
from dataclasses import dataclass
from pathlib import Path

from ai.dataset_pipeline.utils.logger import get_logger

logger = get_logger("dataset_pipeline.edge_case_jsonl_loader")


@dataclass
class EdgeCaseExample:
    """Structured edge case training example"""

    prompt: str
    response: str
    category: str
    difficulty_level: str
    expected_challenges: list[str]
    purpose: str
    source: str
    generated_at: str

    def to_training_format(self) -> dict:
        """Convert to standard training format"""
        return {
            "text": f"Therapist: {self.prompt}\nClient: {self.response}",
            "prompt": self.prompt,
            "response": self.response,
            "metadata": {
                "category": self.category,
                "difficulty_level": self.difficulty_level,
                "expected_challenges": self.expected_challenges,
                "purpose": self.purpose,
                "source": self.source,
                "generated_at": self.generated_at,
                "is_edge_case": True,
                "stage": "stage3_edge_stress_test",
                "crisis_intensity": self.difficulty_level,
                "quality_profile": "edge_crisis",
            },
        }


@dataclass
class EdgeCaseConfig:
    """Configuration for EdgeCaseJSONLLoader"""

    output_path: str = "ai/pipelines/edge_case_pipeline_standalone/output"


class EdgeCaseJSONLLoader:
    """Loader for edge case training data in JSONL format"""

    def __init__(self, config: EdgeCaseConfig | None = None, file_path: Path | None = None):
        self.config = config or EdgeCaseConfig()

        # Allow overriding the file path (e.g. from S3 cache)
        if file_path:
            self.training_file = Path(file_path)
        else:
            self.training_file = Path(self.config.output_path) / "edge_cases_training_format.jsonl"

    def load_edge_cases(self) -> list[EdgeCaseExample]:
        """Load all edge case examples from JSONL file"""
        if not self.training_file.exists():
            logger.warning(f"Edge case training file not found: {self.training_file}")
            logger.info("Run the edge case pipeline first to generate training data")
            return []

        examples = []
        try:
            with open(self.training_file) as f:
                for line_num, line in enumerate(f, 1):
                    try:
                        data = json.loads(line.strip())
                        example = EdgeCaseExample(
                            prompt=data["prompt"],
                            response=data["response"],
                            category=data["category"],
                            difficulty_level=data["difficulty_level"],
                            expected_challenges=data["expected_challenges"],
                            purpose=data.get("purpose", "difficult_client"),
                            source=data.get("source", "edge_case_generation"),
                            generated_at=data.get("generated_at", ""),
                        )
                        examples.append(example)
                    except (json.JSONDecodeError, KeyError) as e:
                        logger.error(f"Error parsing line {line_num}: {e}")
                        continue

            logger.info(f"Loaded {len(examples)} edge case examples from {self.training_file}")
            return examples

        except Exception as e:
            logger.error(f"Failed to load edge case training data: {e}")
            return []

    def load_by_category(self, category: str) -> list[EdgeCaseExample]:
        """Load edge cases filtered by category"""
        all_examples = self.load_edge_cases()
        filtered = [ex for ex in all_examples if ex.category == category]
        logger.info(f"Loaded {len(filtered)} examples for category '{category}'")
        return filtered

    def load_by_difficulty(self, difficulty: str) -> list[EdgeCaseExample]:
        """Load edge cases filtered by difficulty level"""
        all_examples = self.load_edge_cases()
        filtered = [ex for ex in all_examples if ex.difficulty_level == difficulty]
        logger.info(f"Loaded {len(filtered)} examples with difficulty '{difficulty}'")
        return filtered

    def get_statistics(self) -> dict:
        """Get statistics about loaded edge cases"""
        examples = self.load_edge_cases()

        if not examples:
            return {
                "total_examples": 0,
                "categories": {},
                "difficulty_levels": {},
                "challenges": {},
            }

        # Count by category
        categories = {}
        for ex in examples:
            categories[ex.category] = categories.get(ex.category, 0) + 1

        # Count by difficulty
        difficulty_levels = {}
        for ex in examples:
            difficulty_levels[ex.difficulty_level] = (
                difficulty_levels.get(ex.difficulty_level, 0) + 1
            )

        # Count challenges
        challenges = {}
        for ex in examples:
            for challenge in ex.expected_challenges:
                challenges[challenge] = challenges.get(challenge, 0) + 1

        return {
            "total_examples": len(examples),
            "categories": categories,
            "difficulty_levels": difficulty_levels,
            "challenges": challenges,
            "file_path": str(self.training_file),
        }

    def convert_to_training_format(
        self, examples: list[EdgeCaseExample] | None = None
    ) -> list[dict]:
        """Convert edge cases to standard training format"""
        if examples is None:
            examples = self.load_edge_cases()

        training_data = [ex.to_training_format() for ex in examples]
        logger.info(f"Converted {len(training_data)} edge cases to training format")
        return training_data

    def check_pipeline_output_exists(self) -> bool:
        """Check if edge case pipeline has been run and output exists"""
        return self.training_file.exists()

    def get_pipeline_instructions(self) -> str:
        """Get instructions for running the edge case pipeline"""
        return """
To generate edge case training data:

1. Navigate to the edge case pipeline:
   cd ai/pipelines/edge_case_pipeline_standalone/

2. Run the pipeline (choose one method):

   Option A - Jupyter Notebook (recommended):
   jupyter notebook Edge_Case_Generation_Pipeline.ipynb

   Option B - Python script:
   python quick_start.py

   Option C - Custom script:
   from edge_case_generator import EdgeCaseGenerator

   generator = EdgeCaseGenerator(
       api_provider="ollama",  # or "openai", "anthropic"
       model_name="artifish/llama3.2-uncensored",
       output_dir="output"
   )

   prompts = generator.generate_prompts(scenarios_per_category=20)
   conversations = generator.generate_conversations(prompts, max_conversations=500)
   training_data = generator.create_training_format(conversations)

3. Output will be saved to:
   ai/pipelines/edge_case_pipeline_standalone/output/edge_cases_training_format.jsonl

4. Then this loader will automatically find and load the data
"""


def load_edge_case_training_data(pipeline_dir: str | None = None) -> list[dict]:
    """
    Convenience function to load edge case training data

    Args:
        pipeline_dir: Optional path to edge case pipeline output directory

    Returns:
        List of training examples in standard format
    """
    if pipeline_dir:
        config = EdgeCaseConfig(output_path=pipeline_dir)
        loader = EdgeCaseJSONLLoader(config=config)
    else:
        loader = EdgeCaseJSONLLoader()

    if not loader.check_pipeline_output_exists():
        logger.warning("Edge case training data not found!")
        logger.info(loader.get_pipeline_instructions())
        return []

    return loader.convert_to_training_format()


if __name__ == "__main__":
    # Test the loader
    loader = EdgeCaseJSONLLoader()

    logger.info("Edge Case Training Data Loader")
    logger.info("=" * 60)

    if not loader.check_pipeline_output_exists():
        logger.warning("\n‚ùå Edge case training data not found!")
        logger.info(loader.get_pipeline_instructions())
    else:
        logger.info("\n‚úÖ Edge case training data found!")

        # Load and show statistics
        stats = loader.get_statistics()
        logger.info("\nüìä Statistics:")
        logger.info(f"   Total examples: {stats['total_examples']}")
        logger.info(f"   Categories: {len(stats['categories'])}")
        logger.info(f"   Difficulty levels: {stats['difficulty_levels']}")

        logger.info("\nüìÅ Categories:")
        for category, count in sorted(
            stats["categories"].items(), key=lambda x: x[1], reverse=True
        )[:10]:
            logger.info(f"   {category}: {count}")

        logger.info("\n‚ö†Ô∏è Top Challenges:")
        for challenge, count in sorted(
            stats["challenges"].items(), key=lambda x: x[1], reverse=True
        )[:10]:
            logger.info(f"   {challenge}: {count}")

        # Load training data
        training_data = loader.convert_to_training_format()
        logger.info(f"\n‚úÖ Loaded {len(training_data)} training examples")

        if training_data:
            logger.info("\nüìù Sample example:")
            sample = training_data[0]
            logger.info(f"   Category: {sample['metadata']['category']}")
            logger.info(f"   Difficulty: {sample['metadata']['difficulty_level']}")
            logger.info(f"   Text: {sample['text'][:200]}...")
