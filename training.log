2025-08-30 15:46:48,190 - __main__ - INFO - BASE_DIR: /home/vivi/pixelated/ai
2025-08-30 15:46:48,192 - __main__ - INFO - Loaded environment variables from .env file
2025-08-30 15:46:48,198 - __main__ - INFO - Enhanced multi-GPU training system initialized successfully!
2025-08-30 15:46:48,198 - __main__ - INFO - This system includes:
2025-08-30 15:46:48,198 - __main__ - INFO - ✓ Advanced multi-GPU optimizations with DeepSpeed support
2025-08-30 15:46:48,198 - __main__ - INFO - ✓ Enhanced monitoring and logging (TensorBoard + W&B)
2025-08-30 15:46:48,198 - __main__ - INFO - ✓ Comprehensive data validation and quality checks
2025-08-30 15:46:48,198 - __main__ - INFO - ✓ Production-ready features (model versioning, automated testing)
2025-08-30 15:46:48,198 - __main__ - INFO - ✓ Advanced curriculum learning with adaptive progression
2025-08-30 15:46:48,198 - __main__ - INFO - ✓ Automated hyperparameter optimization (optional)
2025-08-30 15:46:48,199 - __main__ - INFO - ✓ Memory management and performance monitoring
2025-08-30 15:46:48,199 - __main__ - INFO - ✓ ONNX export and inference optimization
2025-08-30 15:46:48,199 - __main__ - INFO - ✓ Complete training pipeline with curriculum execution
2025-08-30 15:46:48,199 - __main__ - INFO - ✓ Comprehensive error handling and retry mechanisms
2025-08-30 15:46:48,199 - __main__ - INFO - ✓ Model validation and quality assurance testing
2025-08-30 15:46:48,199 - __main__ - INFO - Starting Enhanced Multi-GPU Training System
2025-08-30 15:46:48,202 - __main__ - WARNING - CUDA not available - applying CONSERVATIVE preset
2025-08-30 15:46:48,202 - __main__ - INFO - Applying CONSERVATIVE memory optimization preset
2025-08-30 15:46:48,202 - __main__ - INFO - Enhanced Training Configuration:
2025-08-30 15:46:48,203 - __main__ - INFO - {
  "base_model": "LatitudeGames/Harbinger-24B",
  "out_dir": "ai/training/checkpoints/harbinger24b-enhanced-qlora",
  "model_version": "1.0.0",
  "memory_optimization_preset": "conservative",
  "project": "pixelated-empathy-enhanced",
  "experiment_name": "harbinger24b-enhanced-training",
  "use_wandb": true,
  "wandb_run_name": "harbinger24b-enhanced-qlora-2xv100s",
  "use_tensorboard": true,
  "dual_persona_dir": "ai/pipelines/dual_persona_training",
  "extra_jsonl": [
    "ai/datasets/merged_mental_health_dataset.jsonl"
  ],
  "max_samples": null,
  "use_curriculum": true,
  "curriculum_glob": "curriculum_phase_*.jsonl",
  "epochs_per_phase": 1,
  "adaptive_curriculum": true,
  "curriculum_loss_threshold": 0.1,
  "curriculum_improvement_threshold": 0.05,
  "min_epochs_per_phase": 1,
  "max_epochs_per_phase": 5,
  "curriculum_validation_steps": 100,
  "max_seq_len": 1024,
  "num_epochs": 3,
  "per_device_train_batch_size": 1,
  "per_device_eval_batch_size": 1,
  "gradient_accumulation_steps": 16,
  "learning_rate": 0.0002,
  "min_learning_rate": 1e-06,
  "warmup_steps": 100,
  "warmup_ratio": 0.1,
  "weight_decay": 0.01,
  "max_grad_norm": 1.0,
  "lr_scheduler_type": "cosine_with_restarts",
  "num_cycles": 0.5,
  "logging_steps": 25,
  "save_steps": 500,
  "eval_steps": 250,
  "save_total_limit": 5,
  "load_best_model_at_end": true,
  "metric_for_best_model": "eval_loss",
  "greater_is_better": false,
  "lora_r": 32,
  "lora_alpha": 64,
  "lora_dropout": 0.1,
  "lora_bias": "none",
  "target_modules": [
    "q_proj",
    "k_proj",
    "v_proj",
    "o_proj",
    "gate_proj",
    "up_proj",
    "down_proj",
    "embed_tokens",
    "lm_head"
  ],
  "use_flash_attn": false,
  "gradient_checkpointing": true,
  "dataloader_pin_memory": false,
  "dataloader_num_workers": 1,
  "dataloader_prefetch_factor": 2,
  "max_memory_per_gpu": "20GB",
  "empty_cache_before_training": true,
  "enable_memory_monitoring": true,
  "memory_monitoring_interval": 50,
  "device_map_strategy": "auto",
  "low_cpu_mem_usage": true,
  "load_in_8bit": false,
  "load_in_4bit": true,
  "use_deepspeed": false,
  "deepspeed_stage": 2,
  "fp16": true,
  "bf16": false,
  "fp16_opt_level": "O2",
  "fp16_full_eval": false,
  "reduce_eval_samples": true,
  "max_eval_samples": 1000,
  "skip_eval_on_phases": false,
  "evaluation_strategy": "steps",
  "eval_delay": 0,
  "early_stopping_patience": 5,
  "early_stopping_threshold": 0.0001,
  "upload_to_hf": true,
  "hf_repo_id": "pixelated-empathy/harbinger24b-enhanced-v1",
  "hf_token": null,
  "create_gguf": true,
  "gguf_quantization": "Q4_K_M",
  "export_onnx": true,
  "optimize_for_inference": true,
  "use_hyperparameter_optimization": false,
  "optuna_n_trials": 20,
  "optuna_storage": null,
  "max_retries": 3,
  "retry_delay": 60,
  "checkpoint_every_n_phases": 1,
  "resume_from_latest": true,
  "auto_find_batch_size": true,
  "fast_dev_run": false,
  "export_only": false,
  "validate_data": true,
  "profile_training": false,
  "run_validation_tests": true,
  "quality_threshold": 0.8,
  "automated_testing": true
}
2025-08-30 15:46:48,204 - __main__ - INFO - TensorBoard logging to: /home/vivi/pixelated/ai/ai/training/checkpoints/harbinger24b-enhanced-qlora/tensorboard
2025-08-30 15:46:48,205 - __main__ - INFO - === System Information ===
2025-08-30 15:46:48,205 - __main__ - INFO - CPU Cores: 8
2025-08-30 15:46:48,205 - __main__ - INFO - System Memory: 31.00 GB
2025-08-30 15:46:48,205 - __main__ - INFO - PyTorch Version: 2.8.0+cu128
2025-08-30 15:46:48,205 - __main__ - INFO - Transformers Available: True
2025-08-30 15:46:48,205 - __main__ - INFO - DeepSpeed Available: False
2025-08-30 15:46:48,205 - __main__ - INFO - FlashAttention Available: False
2025-08-30 15:46:48,205 - __main__ - INFO - Optuna Available: False
2025-08-30 15:46:48,205 - __main__ - INFO - W&B Available: False
2025-08-30 15:46:48,205 - __main__ - INFO - Training configuration saved to: /home/vivi/pixelated/ai/ai/training/checkpoints/harbinger24b-enhanced-qlora/training_config.json
2025-08-30 15:46:48,206 - __main__ - INFO - TensorBoard logging to: /home/vivi/pixelated/ai/ai/training/checkpoints/harbinger24b-enhanced-qlora/tensorboard
2025-08-30 15:46:48,206 - __main__ - INFO - Starting enhanced curriculum training...
2025-08-30 15:46:48,206 - __main__ - INFO - Loading LatitudeGames/Harbinger-24B with enhanced configuration...
2025-08-30 15:46:48,206 - __main__ - INFO - Analyzing GPU memory before model loading...
2025-08-30 15:46:48,206 - __main__ - INFO - Loading tokenizer for LatitudeGames/Harbinger-24B
2025-08-30 15:46:48,272 - __main__ - ERROR - Training failed with error: There was a specific connection error when trying to load LatitudeGames/Harbinger-24B:
401 Client Error: Unauthorized for url: https://huggingface.co/LatitudeGames/Harbinger-24B/resolve/main/config.json (Request ID: Root=1-68b35528-1c6919e37a51dbaa710d16e9;52e04886-ca90-49eb-9258-8f7880ab6a2e)

Invalid credentials in Authorization header
2025-08-30 15:47:54,846 - research.notebooks.enhanced_multi_gpu_training - INFO - BASE_DIR: /home/vivi/pixelated/ai
2025-08-30 15:47:54,847 - research.notebooks.enhanced_multi_gpu_training - INFO - Loaded environment variables from .env file
2025-08-30 17:34:56,824 - research.notebooks.enhanced_multi_gpu_training - INFO - BASE_DIR: /home/vivi/pixelated/ai
2025-08-30 17:34:56,825 - research.notebooks.enhanced_multi_gpu_training - INFO - Loaded environment variables from .env file
2025-08-30 17:34:56,833 - research.notebooks.enhanced_multi_gpu_training - INFO - TensorBoard logging to: /home/vivi/pixelated/ai/ai/training/checkpoints/harbinger24b-enhanced-qlora/tensorboard
2025-08-30 17:34:56,835 - research.notebooks.enhanced_multi_gpu_training - INFO - Executing 1 curriculum phases...
2025-08-30 17:34:56,835 - research.notebooks.enhanced_multi_gpu_training - INFO - 
=== Phase 1/1: test_phase ===
2025-08-30 17:34:56,836 - research.notebooks.enhanced_multi_gpu_training - WARNING - psutil not available - cannot monitor GPU processes
2025-08-30 17:34:56,838 - research.notebooks.enhanced_multi_gpu_training - WARNING - Found GPU process: PID 1234, python
2025-08-30 17:34:56,838 - research.notebooks.enhanced_multi_gpu_training - INFO - Terminated GPU process 1234 (python)
2025-08-30 17:34:56,838 - research.notebooks.enhanced_multi_gpu_training - INFO - Terminated 1 GPU processes
2025-08-30 17:34:58,838 - research.notebooks.enhanced_multi_gpu_training - INFO - Performing aggressive memory cleanup...
2025-08-30 17:34:59,016 - research.notebooks.enhanced_multi_gpu_training - INFO - Aggressive memory cleanup completed
2025-08-30 17:34:59,016 - research.notebooks.enhanced_multi_gpu_training - INFO - TensorBoard logging to: /home/vivi/pixelated/ai/ai/training/checkpoints/harbinger24b-enhanced-qlora/tensorboard
2025-08-30 17:34:59,018 - research.notebooks.enhanced_multi_gpu_training - INFO - Loading LatitudeGames/Harbinger-24B with enhanced configuration...
2025-08-30 17:34:59,018 - research.notebooks.enhanced_multi_gpu_training - INFO - Analyzing GPU memory before model loading...
2025-08-30 17:34:59,018 - research.notebooks.enhanced_multi_gpu_training - INFO - Attempting loading strategy 1/1: test_strategy
2025-08-30 17:34:59,018 - research.notebooks.enhanced_multi_gpu_training - INFO - Model loaded successfully with strategy: test_strategy
2025-08-30 17:34:59,018 - research.notebooks.enhanced_multi_gpu_training - INFO - Gradient checkpointing enabled
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - === Current GPU Memory Usage ===
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - TensorBoard logging to: /home/vivi/pixelated/ai/ai/training/checkpoints/harbinger24b-enhanced-qlora/tensorboard
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - 
============================================================
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - ENHANCED TRAINING SUMMARY
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - ============================================================
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - Total Phases: 3
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - Best Overall Metric: 0.5
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - Training Duration: 2023-01-01T00:00:00 - 2023-01-01T01:00:00
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO - 
Phase Results:
2025-08-30 17:34:59,019 - research.notebooks.enhanced_multi_gpu_training - INFO -   ✓ phase1: Loss=0.5, Time=100s
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO - 
System Features Used:
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO -   - DeepSpeed: ✗
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO -   - FlashAttention: ✗
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO -   - W&B Logging: ✗
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO -   - TensorBoard: ✓
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO -   - Curriculum Learning: ✓
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO - 
Model saved to: /tmp/test
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO - ============================================================
2025-08-30 17:34:59,020 - research.notebooks.enhanced_multi_gpu_training - INFO - TensorBoard logging to: /home/vivi/pixelated/ai/ai/training/checkpoints/harbinger24b-enhanced-qlora/tensorboard
2025-08-30 17:34:59,021 - research.notebooks.enhanced_multi_gpu_training - INFO - Preparing datasets for training...
2025-08-30 17:34:59,021 - research.notebooks.enhanced_multi_gpu_training - INFO - Processing train dataset...
2025-08-30 19:33:33,916 - enhanced_multi_gpu_training - INFO - BASE_DIR: /home/vivi/pixelated/ai
2025-08-30 19:33:33,917 - enhanced_multi_gpu_training - INFO - Loaded environment variables from .env file
2025-08-30 19:33:33,921 - __main__ - INFO - Starting export functionality tests...
2025-08-30 19:33:33,921 - __main__ - INFO - 
1. Testing configuration validation...
2025-08-30 19:33:33,921 - __main__ - INFO - ✓ Config has export_onnx: True
2025-08-30 19:33:33,922 - __main__ - INFO - ✓ Config has create_gguf: True
2025-08-30 19:33:33,922 - __main__ - INFO - ✓ Config has gguf_quantization: Q4_K_M
2025-08-30 19:33:33,922 - __main__ - INFO - 
2. Testing export functionality...
2025-08-30 19:33:33,922 - enhanced_multi_gpu_training - INFO - TensorBoard logging to: /tmp/tmp4ezz_qwg/output/tensorboard
2025-08-30 19:33:33,924 - __main__ - INFO - Testing _export_models method...
2025-08-30 19:33:33,924 - enhanced_multi_gpu_training - INFO - Exporting models...
2025-08-30 19:33:33,924 - enhanced_multi_gpu_training - INFO - ONNX export requested
2025-08-30 19:33:33,924 - enhanced_multi_gpu_training - INFO - Starting ONNX export
2025-08-30 19:33:33,925 - enhanced_multi_gpu_training - INFO - Exporting model to: /tmp/tmp4ezz_qwg/output/exports/model.onnx
2025-08-30 19:33:33,925 - enhanced_multi_gpu_training - WARNING - ONNX library not available, attempting basic torch.onnx export
2025-08-30 19:33:33,925 - enhanced_multi_gpu_training - INFO - Moving model to CPU for ONNX export
2025-08-30 19:33:33,926 - enhanced_multi_gpu_training - INFO - Using dummy input shape: <MagicMock name='mock.shape' id='129332221305104'>
2025-08-30 19:33:33,930 - enhanced_multi_gpu_training - ERROR - ONNX export failed: _create_function_from_trace(): incompatible function arguments. The following argument types are supported:
    1. (name: str, func: Callable, input_tuple: tuple, var_name_lookup_fn: Callable, strict: bool, force_outplace: bool, argument_names: list[str] = []) -> torch._C.ScriptFunction

Invoked with: <MagicMock name='mock._jit_override_qualname' id='129332221366416'>, <MagicMock id='129332647741904'>, (<MagicMock id='129332221228112'>,), <function _create_interpreter_name_lookup_fn.<locals>._get_interpreter_name_for_var at 0x75a081194900>, True, False, []
2025-08-30 19:33:33,931 - enhanced_multi_gpu_training - INFO - For better ONNX export support, install: pip install onnx onnxruntime
2025-08-30 19:33:33,932 - enhanced_multi_gpu_training - INFO - Model saved for manual ONNX conversion: /tmp/tmp4ezz_qwg/output/exports/model_for_onnx_conversion
2025-08-30 19:33:33,933 - enhanced_multi_gpu_training - INFO - Use transformers.onnx or optimum library for conversion
2025-08-30 19:33:33,933 - enhanced_multi_gpu_training - INFO - GGUF export requested with quantization: Q4_K_M
2025-08-30 19:33:33,934 - enhanced_multi_gpu_training - INFO - Starting GGUF export with quantization: Q4_K_M
2025-08-30 19:33:33,934 - enhanced_multi_gpu_training - INFO - Exporting model from /tmp/tmp4ezz_qwg/output to /tmp/tmp4ezz_qwg/output/exports/model-Q4_K_M.gguf
2025-08-30 19:33:33,935 - enhanced_multi_gpu_training - INFO - Attempting GGUF export using transformers library
2025-08-30 19:33:33,936 - enhanced_multi_gpu_training - ERROR - Transformers-based GGUF preparation failed: Unrecognized model in /tmp/tmp4ezz_qwg/output. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: aimv2, aimv2_vision_model, albert, align, altclip, arcee, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, bitnet, blenderbot, blenderbot-small, blip, blip-2, blip_2_qformer, bloom, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, cohere2_vision, colpali, colqwen2, conditional_detr, convbert, convnext, convnextv2, cpmant, csm, ctrl, cvt, d_fine, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v2, deepseek_v3, deepseek_vl, deepseek_vl_hybrid, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dia, diffllama, dinat, dinov2, dinov2_with_registers, distilbert, doge, donut-swin, dots1, dpr, dpt, efficientformer, efficientloftr, efficientnet, electra, emu3, encodec, encoder-decoder, eomt, ernie, ernie4_5, ernie4_5_moe, ernie_m, esm, evolla, exaone4, falcon, falcon_h1, falcon_mamba, fastspeech2_conformer, fastspeech2_conformer_with_hifigan, flaubert, flava, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, gemma3n, gemma3n_audio, gemma3n_text, gemma3n_vision, git, glm, glm4, glm4_moe, glm4v, glm4v_text, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gpt_oss, gptj, gptsan-japanese, granite, granite_speech, granitemoe, granitemoehybrid, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hgnet_v2, hiera, hubert, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, internvl, internvl_vision, jamba, janus, jetmoe, jukebox, kosmos-2, kyutai_speech_to_text, layoutlm, layoutlmv2, layoutlmv3, led, levit, lfm2, lightglue, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, mgp-str, mimi, minimax, mistral, mistral3, mixtral, mlcd, mllama, mm-grounding-dino, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, modernbert-decoder, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, owlv2, owlvit, paligemma, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, perception_encoder, perception_lm, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_omni, qwen2_5_vl, qwen2_5_vl_text, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen2_vl_text, qwen3, qwen3_moe, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam_hq, sam_hq_vision_model, sam_vision_model, seamless_m4t, seamless_m4t_v2, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip_vision_model, smollm3, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, t5gemma, table-transformer, tapas, textnet, time_series_transformer, timesfm, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, vjepa2, voxtral, voxtral_encoder, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xlstm, xmod, yolos, yoso, zamba, zamba2, zoedepth
2025-08-30 19:33:33,936 - enhanced_multi_gpu_training - INFO - For complete GGUF export functionality, install llama-cpp-python:
2025-08-30 19:33:33,936 - enhanced_multi_gpu_training - INFO - pip install llama-cpp-python
2025-08-30 19:33:33,936 - enhanced_multi_gpu_training - INFO - Or clone llama.cpp repository and use convert.py script
2025-08-30 19:33:33,936 - __main__ - INFO - ✓ Export directory created successfully
2025-08-30 19:33:33,936 - __main__ - INFO - ✓ Export functionality test completed without errors
2025-08-30 19:33:33,937 - __main__ - INFO - 
==================================================
2025-08-30 19:33:33,937 - __main__ - INFO - TEST SUMMARY
2025-08-30 19:33:33,937 - __main__ - INFO - ==================================================
2025-08-30 19:33:33,937 - __main__ - INFO - Configuration test: PASS
2025-08-30 19:33:33,937 - __main__ - INFO - Export functionality test: PASS
2025-08-30 19:33:33,937 - __main__ - INFO - ✓ All tests passed!
