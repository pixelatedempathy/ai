#!/usr/bin/env python3
"""
Lightning.ai H100 Deployment Orchestrator
One-command deployment preparation for therapeutic AI training.

This script orchestrates the complete deployment pipeline:
1. Validates unified dataset readiness
2. Creates Lightning.ai deployment package
3. Generates all required scripts and configurations
4. Provides upload instructions for Lightning.ai Studio
"""

import json
import logging
import shutil
from pathlib import Path
from typing import Dict, List
import sys
import zipfile
from datetime import datetime

# Import path utilities
from path_utils import get_workspace_root, get_unified_training_dir, get_lightning_dir, get_scripts_dir

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LightningDeploymentOrchestrator:
    """Orchestrate complete Lightning.ai H100 deployment preparation"""
    
    def __init__(self):
        # Use dynamic path resolution
        self.workspace_root = get_workspace_root()
        self.unified_dataset_path = get_unified_training_dir()
        self.deployment_dir = get_lightning_dir() / "h100_deployment"
        self.deployment_dir.mkdir(parents=True, exist_ok=True)
        
        # Import deployment modules
        sys.path.append(str(get_scripts_dir()))
        
    def run_readiness_validation(self) -> Dict:
        """Run comprehensive readiness validation"""
        logger.info("ğŸ” Running deployment readiness validation...")
        
        try:
            from validate_deployment_readiness import DeploymentValidator
            
            validator = DeploymentValidator()
            report = validator.generate_readiness_report()
            
            if report["overall_ready"]:
                logger.info("âœ… Deployment readiness validation passed!")
            else:
                logger.warning("âš ï¸  Deployment readiness issues detected")
                for issue in report["critical_issues"]:
                    logger.warning(f"   â€¢ {issue}")
            
            return report
            
        except Exception as e:
            logger.error(f"âŒ Error running readiness validation: {e}")
            return {"overall_ready": False, "error": str(e)}
    
    def prepare_deployment_package(self) -> Dict:
        """Prepare complete Lightning.ai deployment package"""
        logger.info("ğŸ“¦ Preparing Lightning.ai H100 deployment package...")
        
        try:
            from lightning_h100_deployment import LightningH100Deployer
            
            deployer = LightningH100Deployer(self.unified_dataset_path)
            
            # Validate dataset
            validation_results = deployer.validate_unified_dataset()
            
            if not validation_results["dataset_ready"]:
                raise RuntimeError("Unified dataset not ready for deployment")
            
            # Create all deployment components
            training_script = deployer.create_lightning_training_script()
            config_file = deployer.create_deployment_config(validation_results)
            requirements_file = deployer.create_requirements_file()
            data_prep_script = deployer.create_data_preparation_script()
            deployment_guide = deployer.create_deployment_instructions(validation_results)
            
            # Package everything
            package_dir = deployer.package_for_deployment()
            
            return {
                "success": True,
                "package_dir": package_dir,
                "validation_results": validation_results,
                "components_created": [
                    str(training_script),
                    str(config_file),
                    str(requirements_file),
                    str(data_prep_script),
                    str(deployment_guide)
                ]
            }
            
        except Exception as e:
            logger.error(f"âŒ Error preparing deployment package: {e}")
            return {"success": False, "error": str(e)}
    
    def create_studio_setup_package(self) -> Dict:
        """Create Lightning Studio setup package"""
        logger.info("ğŸ› ï¸  Creating Lightning Studio setup package...")
        
        try:
            from lightning_studio_setup import LightningStudioSetup
            
            # Copy studio setup script to deployment
            studio_script_source = self.workspace_root / "ai/scripts/lightning_studio_setup.py"
            studio_script_target = self.deployment_dir / "lightning_studio_setup.py"
            
            if studio_script_source.exists():
                shutil.copy2(studio_script_source, studio_script_target)
                logger.info("âœ… Studio setup script prepared")
            
            return {"success": True, "studio_script": str(studio_script_target)}
            
        except Exception as e:
            logger.error(f"âŒ Error creating studio setup package: {e}")
            return {"success": False, "error": str(e)}
    
    def create_deployment_archive(self, package_dir: Path) -> Path:
        """Create deployable archive for easy upload"""
        logger.info("ğŸ—œï¸  Creating deployment archive...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        archive_name = f"therapeutic_ai_h100_deployment_{timestamp}.zip"
        archive_path = self.deployment_dir / archive_name
        
        with zipfile.ZipFile(archive_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            # Add all files from package directory
            for file_path in package_dir.rglob("*"):
                if file_path.is_file():
                    arcname = file_path.relative_to(package_dir)
                    zipf.write(file_path, arcname)
            
            # Add studio setup script
            studio_script = self.deployment_dir / "lightning_studio_setup.py"
            if studio_script.exists():
                zipf.write(studio_script, "lightning_studio_setup.py")
        
        logger.info(f"âœ… Deployment archive created: {archive_path}")
        return archive_path
    
    def generate_upload_instructions(self, archive_path: Path, validation_results: Dict) -> Path:
        """Generate detailed upload and deployment instructions"""
        logger.info("ğŸ“‹ Generating upload instructions...")
        
        total_conversations = validation_results.get("total_conversations", 0)
        expert_distribution = validation_results.get("expert_distribution", {})
        
        instructions = f'''# Lightning.ai H100 Deployment Instructions
## ğŸš€ Therapeutic AI Training with Breakthrough Intelligent Dataset

### ğŸ“Š **What You're Deploying**
- **Total Conversations:** {total_conversations:,} high-quality therapeutic training pairs
- **Innovation:** First AI trained on intelligent pattern-analyzed data (no generic questions!)
- **Expert Distribution:** {expert_distribution}
- **Expected Training Time:** 6-12 hours on H100
- **Model Output:** ~1.5GB LoRA adapters for therapeutic conversation AI

### ğŸ¯ **Mission**
Deploy the world's first therapeutic AI trained on contextually appropriate Q/A pairs generated by our breakthrough multi-pattern intelligent agent.

---

## ğŸ“¦ **Step 1: Upload to Lightning.ai Studio**

### Upload Archive
1. **Login to Lightning.ai** â†’ Create new Studio
2. **Upload Archive:** `{archive_path.name}`
3. **Extract in Studio:**
   ```bash
   unzip {archive_path.name}
   cd therapeutic_ai_h100_deployment/
   ```

### Alternative: Manual Upload
If archive is too large, upload files individually:
- Upload all files from deployment package
- Ensure data/ directory contains all .json files
- Verify all Python scripts are present

---

## ğŸ› ï¸  **Step 2: Studio Environment Setup**

### Run Automated Setup
```bash
python lightning_studio_setup.py
```

### Manual Setup (if needed)
```bash
# Install dependencies
pip install torch>=2.0.0 lightning>=2.1.0 transformers>=4.35.0 peft>=0.6.0

# Verify H100 GPU
python -c "import torch; print(f'GPU: {{torch.cuda.get_device_name(0)}}')"

# Setup WandB (optional but recommended)
wandb login
```

---

## ğŸ”¥ **Step 3: Launch H100 Training**

### Quick Start
```bash
# Prepare data
python prepare_data.py

# Launch training
python train_therapeutic_ai.py
```

### Advanced Launch (with monitoring)
```bash
# Use the training launcher for better monitoring
python scripts/launch_training.py
```

---

## ğŸ“ˆ **Step 4: Monitor Training**

### Real-time Monitoring
- **Lightning Logs:** `./lightning_logs/` 
- **WandB Dashboard:** Real-time loss, perplexity, expert utilization
- **GPU Utilization:** Should maintain >90% on H100

### Key Metrics to Watch
- **Training Loss:** Should decrease steadily
- **Validation Loss:** Target < 1.5
- **Perplexity:** Target < 2.5
- **Expert Balance:** All 4 experts should be utilized

### Training Checkpoints
- **Automatic Saves:** Every 100 steps
- **Best Model:** Saved based on validation loss
- **Early Stopping:** If validation loss increases for 3 evaluations

---

## ğŸ¯ **Expected Results**

### Training Progression
- **Hours 1-2:** Rapid initial loss decrease
- **Hours 3-6:** Steady improvement, expert specialization emerges
- **Hours 6-12:** Fine-tuning, validation convergence

### Success Indicators
- âœ… **Validation Loss < 1.5:** Model learning therapeutic patterns
- âœ… **Balanced Expert Use:** All experts contributing (20-30% each)
- âœ… **Coherent Responses:** Generated text is therapeutically appropriate
- âœ… **No Catastrophic Forgetting:** Base language capabilities preserved

---

## ğŸ”§ **Troubleshooting**

### Common Issues
| Issue | Solution |
|-------|----------|
| OOM Error | Reduce batch_size to 4 in config |
| Slow Training | Check H100 utilization with `nvidia-smi` |
| Poor Quality | Increase LoRA rank to 32 |
| Expert Imbalance | Adjust expert sampling in training loop |

### Performance Optimization
```bash
# Enable TensorFloat-32 for faster training
export TORCH_ALLOW_TF32_CUBLAS_OVERRIDE=1

# Optimal memory settings
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
```

---

## ğŸ‰ **Post-Training Deployment**

### Save Trained Model
```bash
# Model automatically saved to ./therapeutic_ai_final/
ls -la therapeutic_ai_final/
```

### Test Model Quality
```bash
# Quick quality test
python -c "
from transformers import AutoTokenizer, AutoModelForCausalLM
tokenizer = AutoTokenizer.from_pretrained('./therapeutic_ai_final')
model = AutoModelForCausalLM.from_pretrained('./therapeutic_ai_final')
print('Model loaded successfully!')
"
```

### Upload to HuggingFace Hub
```bash
# Optional: Share your trained model
huggingface-cli login
python -c "
from transformers import AutoTokenizer, AutoModelForCausalLM
tokenizer = AutoTokenizer.from_pretrained('./therapeutic_ai_final')
model = AutoModelForCausalLM.from_pretrained('./therapeutic_ai_final')
model.push_to_hub('your-username/therapeutic-ai-breakthrough')
tokenizer.push_to_hub('your-username/therapeutic-ai-breakthrough')
"
```

---

## ğŸŒŸ **What Makes This Special**

### Breakthrough Innovation
- **First therapeutic AI** trained on intelligent pattern-analyzed conversations
- **Solves "generic question problem"** that plagued previous systems
- **Multi-expert architecture** with specialized therapeutic knowledge
- **H100 optimization** for fastest possible training

### Quality Guarantee
- Every Q/A pair validated for semantic coherence
- Actual questions extracted from therapeutic interviews
- Context-aware prompt generation for authentic conversations
- Comprehensive deduplication and quality assessment

---

## ğŸ“ **Support & Next Steps**

### If Training Succeeds
1. **Validate Model Quality** with therapeutic test scenarios
2. **Deploy to Production** API for therapeutic applications
3. **Iterate and Improve** based on real-world usage
4. **Scale Up** with larger datasets and models

### If Issues Arise
1. **Check Logs:** `lightning_logs/` for detailed error information
2. **Reduce Complexity:** Lower batch size or LoRA rank
3. **Verify Data:** Ensure all .json files loaded correctly
4. **Contact Support:** Provide logs and error messages

---

**This deployment represents a breakthrough in therapeutic AI - the first system trained on truly contextual, high-quality therapeutic conversations. Expected completion: 6-12 hours for world-class therapeutic AI.** ğŸš€

### Archive Info
- **Archive:** `{archive_path.name}`
- **Size:** {archive_path.stat().st_size / (1024*1024):.1f} MB
- **Created:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
'''
        
        instructions_path = self.deployment_dir / "LIGHTNING_DEPLOYMENT_INSTRUCTIONS.md"
        with open(instructions_path, 'w', encoding='utf-8') as f:
            f.write(instructions)
        
        logger.info(f"âœ… Upload instructions created: {instructions_path}")
        return instructions_path
    
    def create_deployment_summary(self, results: Dict) -> Dict:
        """Create final deployment summary"""
        summary = {
            "deployment_timestamp": datetime.now().isoformat(),
            "status": "ready" if results.get("readiness_validation", {}).get("overall_ready", False) else "requires_attention",
            "components": {
                "unified_dataset": results.get("readiness_validation", {}).get("validations", {}).get("dataset", {}).get("ready_for_deployment", False),
                "lightning_scripts": results.get("package_preparation", {}).get("success", False),
                "studio_setup": results.get("studio_setup", {}).get("success", False),
                "deployment_archive": results.get("archive_path") is not None,
                "instructions": results.get("instructions_path") is not None
            },
            "dataset_stats": results.get("package_preparation", {}).get("validation_results", {}),
            "next_actions": [],
            "files_created": results.get("files_created", [])
        }
        
        # Determine next actions
        if summary["status"] == "ready":
            summary["next_actions"] = [
                f"ğŸš€ Upload {results.get('archive_path', 'deployment archive')} to Lightning.ai Studio",
                "ğŸ› ï¸  Run lightning_studio_setup.py in Studio environment", 
                "ğŸ”¥ Launch training with train_therapeutic_ai.py",
                "ğŸ“ˆ Monitor training progress for 6-12 hours"
            ]
        else:
            issues = results.get("readiness_validation", {}).get("critical_issues", [])
            summary["next_actions"] = [
                "ğŸ”§ Resolve deployment readiness issues:",
                *[f"   â€¢ {issue}" for issue in issues],
                "ğŸ”„ Re-run deployment preparation after fixes"
            ]
        
        return summary
    
    def run_complete_deployment_preparation(self) -> Dict:
        """Run complete deployment preparation pipeline"""
        logger.info("ğŸš€ Starting complete Lightning.ai H100 deployment preparation...")
        logger.info("=" * 80)
        
        results = {
            "success": False,
            "files_created": [],
            "errors": []
        }
        
        # Step 1: Readiness validation
        logger.info("Step 1/5: Validating deployment readiness...")
        readiness_report = self.run_readiness_validation()
        results["readiness_validation"] = readiness_report
        
        if not readiness_report.get("overall_ready", False):
            logger.error("âŒ Deployment readiness validation failed!")
            logger.error("   Address issues before proceeding with deployment")
            results["errors"].append("Readiness validation failed")
            return results
        
        # Step 2: Prepare deployment package
        logger.info("Step 2/5: Preparing Lightning.ai deployment package...")
        package_results = self.prepare_deployment_package()
        results["package_preparation"] = package_results
        
        if not package_results.get("success", False):
            logger.error("âŒ Failed to prepare deployment package!")
            results["errors"].append("Package preparation failed")
            return results
        
        results["files_created"].extend(package_results.get("components_created", []))
        
        # Step 3: Create studio setup package
        logger.info("Step 3/5: Creating Studio setup package...")
        studio_results = self.create_studio_setup_package()
        results["studio_setup"] = studio_results
        
        if studio_results.get("success", False):
            results["files_created"].append(studio_results["studio_script"])
        
        # Step 4: Create deployment archive
        logger.info("Step 4/5: Creating deployment archive...")
        package_dir = Path(package_results["package_dir"])
        archive_path = self.create_deployment_archive(package_dir)
        results["archive_path"] = str(archive_path)
        results["files_created"].append(str(archive_path))
        
        # Step 5: Generate upload instructions
        logger.info("Step 5/5: Generating upload instructions...")
        validation_results = package_results["validation_results"]
        instructions_path = self.generate_upload_instructions(archive_path, validation_results)
        results["instructions_path"] = str(instructions_path)
        results["files_created"].append(str(instructions_path))
        
        # Create deployment summary
        deployment_summary = self.create_deployment_summary(results)
        summary_path = self.deployment_dir / "deployment_summary.json"
        with open(summary_path, 'w') as f:
            json.dump(deployment_summary, f, indent=2)
        
        results["deployment_summary"] = deployment_summary
        results["success"] = True
        
        # Final summary
        logger.info("=" * 80)
        logger.info("ğŸ‰ Lightning.ai H100 Deployment Preparation Complete!")
        logger.info("=" * 80)
        
        dataset_stats = validation_results
        logger.info(f"ğŸ“Š Dataset Ready: {dataset_stats['total_conversations']:,} conversations")
        logger.info(f"ğŸ§  Expert Distribution: {dataset_stats['expert_distribution']}")
        logger.info(f"ğŸ“¦ Deployment Archive: {archive_path.name} ({archive_path.stat().st_size / (1024*1024):.1f} MB)")
        logger.info(f"ğŸ“ Deployment Directory: {self.deployment_dir}")
        
        logger.info("\nğŸš€ Next Steps:")
        for action in deployment_summary["next_actions"]:
            logger.info(f"   {action}")
        
        logger.info(f"\nğŸ“‹ Full Instructions: {instructions_path}")
        
        return results

def main():
    """Main deployment orchestration function"""
    logger.info("ğŸ¯ Lightning.ai H100 Therapeutic AI Deployment Orchestrator")
    logger.info("   Preparing breakthrough intelligent therapeutic dataset for H100 training...")
    
    orchestrator = LightningDeploymentOrchestrator()
    results = orchestrator.run_complete_deployment_preparation()
    
    return results["success"]

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)