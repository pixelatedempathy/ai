from ai.inference
from ai.pixel
from ai.dataset_pipeline
from .\1 import
from typing import Dict, List, Optional, Union, Any, Tuple, Callable
import pytest
#!/usr/bin/env python3
"""
Quick test of the updated crisis generator
Test one scenario to make sure it works before running the full batch
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from .abliterated_crisis_generator import AbliteratedCrisisGenerator, CrisisScenario
import asyncio

async def test_single_crisis_generation():
    """Test generating one crisis conversation"""
    
    print("ğŸ§ª QUICK CRISIS GENERATOR TEST")
    print("=" * 50)
    
    # Initialize generator
    try:
        generator = AbliteratedCrisisGenerator()
        print("âœ… Generator initialized successfully")
    except Exception as e:
        print(f"âŒ Generator initialization failed: {e}")
        return False
    
    # Create a test scenario
    test_scenario = CrisisScenario(
        scenario_id="test_suicide_ideation",
        crisis_type="suicidal_ideation",
        intensity_level=8,
        demographic="college_student_20s",
        situation_context="Academic pressure, social isolation, recent breakup",
        expected_duration=6
    )
    
    print(f"\nğŸ¯ Testing scenario: {test_scenario.crisis_type}")
    print(f"   Intensity: {test_scenario.intensity_level}/10")
    print(f"   Context: {test_scenario.situation_context}")
    
    # Generate conversation
    try:
        print("\nğŸ”„ Generating crisis conversation...")
        conversation = generator.generate_crisis_conversation(test_scenario)
        
        print("âœ… Generation successful!")
        print(f"ğŸ“Š Conversation ID: {conversation['conversation_id']}")
        print(f"ğŸ­ Turns generated: {len(conversation['turns'])}")
        print(f"ğŸš¨ Crisis indicators: {len(conversation['crisis_indicators_detected'])}")
        print(f"ğŸ“ˆ Quality scores: {conversation['conversation_quality']}")
        
        # Show a sample of the conversation
        print(f"\nğŸ“ SAMPLE CONVERSATION:")
        print("-" * 30)
        
        for i, turn in enumerate(conversation['turns'][:4]):  # Show first 4 turns
            speaker = "User" if turn['speaker'] == 'user' else "Assistant"
            message = turn['message'][:100] + "..." if len(turn['message']) > 100 else turn['message']
            print(f"{speaker}: {message}")
            if i < len(conversation['turns']) - 1:
                print()
        
        if len(conversation['turns']) > 4:
            print(f"... ({len(conversation['turns']) - 4} more turns)")
        
        print(f"\nğŸ¯ Crisis indicators detected:")
        for indicator in conversation['crisis_indicators_detected'][:5]:
            print(f"   â€¢ {indicator}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Generation failed: {e}")
        return False

if __name__ == "__main__":
    success = asyncio.run(test_single_crisis_generation())
    
    if success:
        print(f"\nğŸ‰ QUICK TEST SUCCESSFUL!")
        print("âœ… Crisis generator is working with OpenAI API")
        print("ğŸš€ Ready to run full crisis conversation library generation")
    else:
        print(f"\nâŒ QUICK TEST FAILED")
        print("ğŸ”§ Need to debug further before running full generation")
