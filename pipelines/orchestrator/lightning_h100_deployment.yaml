# Lightning.ai H100 Training Deployment Configuration
# For Pixelated Empathy AI - Therapeutic Conversation Model

name: pixelated-empathy-ai-training
description: "Training configuration for Pixelated Empathy AI therapeutic conversation model on H100 GPUs"

# Hardware Configuration
hardware:
  accelerators: "H100"
  num_nodes: 1
  num_devices: 8  # 8 H100 GPUs per node
  memory_per_device: "80GB"  # H100 memory
  cpu_cores: 64
  system_memory: "512GB"
  storage:
    type: "nvme-ssd"
    size: "2TB"
    mount_point: "/workspace"

# Training Configuration
training:
  model:
    base_model: "mistralai/Mixtral-8x22B-Instruct-v0.1"
    tokenizer: "mistralai/Mixtral-8x22B-Instruct-v0.1"
    precision: "bf16"  # BFloat16 for H100

  datasets:
    training:
      path: "ai/training_data_consolidated/final_datasets/ULTIMATE_FINAL_DATASET.jsonl"
      size: "2.6GB"
      record_count: 608497
      format: "jsonl"

    validation:
      path: "ai/training_data_consolidated/final_datasets/pixelated_empathy_val_20250526_174637.jsonl"
      size: "191MB"
      format: "jsonl"

    test:
      path: "ai/training_data_consolidated/final_datasets/pixelated_empathy_test_20250526_174637.jsonl"
      size: "190MB"
      format: "jsonl"

    psychology_knowledge:
      path: "ai/training_data_consolidated/psychology_knowledge/psychology_knowledge_base_optimized.json"
      size: "19MB"
      concept_count: 4867
      format: "json"

  hyperparameters:
    # Training parameters
    batch_size: 1024
    per_device_train_batch_size: 2
    gradient_accumulation_steps: 64
    learning_rate: 1e-5
    num_epochs: 3
    warmup_steps: 1000
    weight_decay: 0.01

    # Model parameters
    max_seq_length: 4096
    gradient_checkpointing: true
    flash_attention: true

    # Optimization
    optimizer: "adamw"
    lr_scheduler_type: "cosine"
    max_grad_norm: 1.0

  # Safety and Quality Controls
  safety_protocols:
    content_filtering:
      enabled: true
      block_categories: ["violence", "hate_speech", "sexual_content", "illegal_activities"]
      confidence_threshold: 0.95

    bias_detection:
      enabled: true
      bias_types: ["gender", "racial", "cultural", "socioeconomic"]
      detection_sensitivity: 0.8

    privacy_protection:
      enabled: true
      pii_types: ["names", "addresses", "phone_numbers", "emails", "ssn"]
      redaction_method: "masking"

    emotional_safety:
      enabled: true
      crisis_intervention_enabled: true
      suicide_prevention_protocol: true
      escalation_procedures: ["human_supervisor_notification", "emergency_services_contact"]

    ethical_guidelines:
      enabled: true
      therapist_role_maintenance: true
      avoid_personal_relationships: true
      confidentiality_enforcement: true

# Output Configuration
output:
  model_artifacts:
    path: "/workspace/model_output"
    checkpoints:
      save_steps: 500
      save_total_limit: 5
      save_strategy: "steps"

  logs:
    path: "/workspace/logs"
    logging_steps: 10
    log_level: "info"

  metrics:
    path: "/workspace/metrics"
    evaluation_steps: 1000

# Environment Configuration
environment:
  python_version: "3.10"
  framework: "PyTorch Lightning"
  additional_packages:
    - "transformers>=4.35.0"
    - "datasets>=2.14.0"
    - "accelerate>=0.23.0"
    - "bitsandbytes>=0.41.0"
    - "peft>=0.6.0"
    - "trl>=0.7.0"
    - "wandb>=0.15.0"
    - "sentence-transformers>=2.2.0"

# Deployment Metadata
metadata:
  project: "pixelated-empathy-ai"
  version: "1.0.0"
  created_by: "Claude Code Dataset Pipeline"
  created_date: "2025-11-04"
  target_platform: "Lightning.ai H100"
  estimated_training_time: "24-48 hours"
  estimated_cost: "$2000-4000"

# Next Steps
next_steps:
  - "Deploy training package to Lightning.ai H100 cluster"
  - "Integrate 4,867 psychology concepts into base model"
  - "Execute training with therapeutic accuracy target >80%"
  - "Validate crisis detection and safety compliance"
  - "Deploy functional Pixel AI for beta testing"